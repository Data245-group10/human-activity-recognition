{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pathlib\n",
    "import csv\n",
    "import tqdm # This library enables the timer in the \"Main Script\" block.\n",
    "import pandas as pd # pandas used to normalize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_only = False\n",
    "    # If this is enabled, then no files will be created.\n",
    "    # Instead only the header will be printed so you can see the columns you'll get.\n",
    "    \n",
    "include_activity_letter     = True\n",
    "include_binned_distrubution = False\n",
    "number_of_bins = 10 # 10 is used by the publishers.\n",
    "\n",
    "base_filename = 'corrected_categories_no_bins_'\n",
    "    # Use a base_filname to differentiate datasets.\n",
    "    # The name should end with an underscore.  Example:\n",
    "    #     'no_bins_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "The utility functions do not contribute significantly to understanding of the data model, so you should not have to read the code in this section unless there is an issue.  An underscore begins the name of each utility function to distinguish them from similarly-named functions in other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mean( data):\n",
    "    return sum( data)/ float( len( data))\n",
    "\n",
    "def _std_dev(data):\n",
    "    mean = _mean( data)\n",
    "    return math.sqrt(sum( [(mean - d)**2 for d in data])) / len(data)\n",
    "\n",
    "def _abs_dev( data):\n",
    "    mean = _mean( data)\n",
    "    return sum( [abs( mean - d) for d in data]) / len(data)\n",
    "\n",
    "def _min_max( data): \n",
    "    '''Helper function for self.generate_bins()'''\n",
    "    _min = data[0]\n",
    "    _max = data[0]\n",
    "    for d in data:\n",
    "        if d < _min:\n",
    "            _min = d\n",
    "        if d > _max:\n",
    "            _max = d\n",
    "    return _min, _max\n",
    "\n",
    "def _bin_upper_edges( data, n):\n",
    "    '''Helper function for self.generate_bins()'''\n",
    "    lower_bound, upper_bound = _min_max( data)\n",
    "    _range = upper_bound - lower_bound\n",
    "    interval = _range / float( n)\n",
    "    return [ lower_bound + i * interval for i in range( n-1)]+[upper_bound]\n",
    "\n",
    "def _bin_proportions( data, n):\n",
    "    '''Helper function for self.generate_bins()'''\n",
    "    upper_edges = _bin_upper_edges( data, n)\n",
    "    count = [0 for _ in range( n)]\n",
    "    for d in data:\n",
    "        counted = False\n",
    "        for i in range( n-1):\n",
    "            if not counted and d <= upper_edges[ i]:\n",
    "                counted = True\n",
    "                count[ i] += 1\n",
    "        if not counted:\n",
    "            count[ -1] += 1\n",
    "    total = len( data)\n",
    "    return [c/float(total) for c in count]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures\n",
    "\n",
    "This primary transformation is chuncking the data into ten-second intervals, so there are two custom data structures: a **RawTimeSeriesData** object will contain a single time-series data point, and a **TenSecondInterval** object will control access to the transformed data.\n",
    "\n",
    "## Data Structures: RawTimeSeriesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawTimeSeriesData:\n",
    "    ''' RawTimeSeriesData encapsulates access to raw data.'''\n",
    "    def __init__( self, data_list):\n",
    "        self.subject_id = int(   data_list[0]) # an integer, 1600-1650\n",
    "        self.activity   = str(   data_list[1]) # a letter, A-S\n",
    "        self.timestamp  = int(   data_list[2]) # an integer, Linux Time\n",
    "        self.x          = float( data_list[3]) # x, y, z are numbers, possibly negative\n",
    "        self.y          = float( data_list[4])\n",
    "        self.z          = float( data_list[5][:-1]) # lines end with a semicolon\n",
    "        \n",
    "    def __str__( self):\n",
    "        return f\"Record of {self.subject_id} at {self.timestamp}: {self.x}, {self.y}, {self.z}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures: TenSecondInterval\n",
    "\n",
    "Technically, the interval may not be exactly 10 seconds long - instead the size is exactly 200 data points.  Sensors are supposed to be polled 20 times/second but the actual frequency may have vary, since the device being used may prioritize other tasks for CPU time.  A choice had to be made between using the same time interval for each chunk and ensuring that each chunk has the same number of data.  We went with the second option for statistical reasons - it keeps the resulting dataset-of-chunks homoskedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TenSecondInterval:\n",
    "    ''' TenSecondInterval encapsulates access to transformed data.\n",
    "    \n",
    "    \n",
    "    Target Attributes (4 variables)\n",
    "    -------------------------------\n",
    "        activity        : a letter , A-S\n",
    "        activity_cat_nh : a boolean, is this a non-hand activity?\n",
    "        activity_cat_hg : a boolean, is this a hand/ general activity?\n",
    "        activity_cat_he : a boolean, is this a hand/ eating activity?\n",
    "        \n",
    "    Data Attributes \n",
    "    ----------------\n",
    "        Summary Statistics   : 10 variables\n",
    "        Binned Distributions : 30 variables\n",
    "    '''\n",
    "    def __init__( self, raw_data_list):\n",
    "        ''' raw_data_list : a list of RawTimeSeriesData objects\n",
    "        '''\n",
    "        self.data = raw_data_list\n",
    "        self.activity = self.data[0].activity\n",
    "        self.generate_summary_stats()\n",
    "        self.generate_bins()\n",
    "    \n",
    "    @property\n",
    "    def activity_onehot( self):\n",
    "        temp = [0] * 18\n",
    "        if self.activity < 'N':\n",
    "            temp[ ord( self.activity) - 65] = 1\n",
    "        else:\n",
    "            temp[ ord( self.activity) - 66] = 1\n",
    "        return temp\n",
    "    \n",
    "    @property\n",
    "    def cat_nonhand( self):\n",
    "        return self.activity in { 'A', 'B', 'C', 'D', 'E', 'M'}\n",
    "    \n",
    "    @property\n",
    "    def cat_hand_general( self):\n",
    "        return self.activity in { 'F', 'G', 'O', 'P', 'Q',' R', 'S'}\n",
    "    \n",
    "    @property\n",
    "    def cat_hand_eating( self):\n",
    "        return self.activity in { 'H', 'I', 'J', 'K', 'L'}\n",
    "    \n",
    "    @property\n",
    "    def cat_hand_all( self):\n",
    "        return self.cat_hand_general | self.cat_hand_eating\n",
    "    \n",
    "    @property\n",
    "    def targets( self):\n",
    "        return self.activity_onehot + [\n",
    "            int(self.cat_nonhand), \n",
    "            int(self.cat_hand_general), \n",
    "            int(self.cat_hand_eating), \n",
    "            int(self.cat_hand_all)]\n",
    "    \n",
    "    def generate_bins( self):\n",
    "        '''\n",
    "        Binned Distributions (30 variables)\n",
    "        -----------------------------------\n",
    "                # The bins divide (max - min) into 10 equally-sized segments.\n",
    "            x_bin_0, x_bin_1, ..., x_bin_9 : a proportion\n",
    "            y_bin_0, y_bin_1, ..., y_bin_9 : a proportion\n",
    "            z_bin_0, z_bin_1, ..., z_bin_9 : a proportion\n",
    "        ''' \n",
    "        self.x_bin = _bin_proportions( [d.x for d in self.data], number_of_bins)\n",
    "        self.y_bin = _bin_proportions( [d.y for d in self.data], number_of_bins)\n",
    "        self.z_bin = _bin_proportions( [d.z for d in self.data], number_of_bins)\n",
    "    \n",
    "    def generate_summary_stats( self):\n",
    "        '''\n",
    "        Summary Statistics (10 variables)\n",
    "        ---------------------------------\n",
    "            {x,y,z}_mean    : the mean value\n",
    "            {x,y,z}_std_dev : standard deviation\n",
    "            {x,y,z}_abs_dev : mean absolute deviation\n",
    "            resultant       : mean resultant value where resultant =\n",
    "                = sqrt( x^2 + y^2 + z^2) # averaged over all data points\n",
    "        '''\n",
    "        data      = [d.x for d in self.data]\n",
    "        self.x_mean    = _mean(    data)\n",
    "        self.x_std_dev = _std_dev( data)\n",
    "        self.x_abs_dev = _abs_dev( data)\n",
    "        \n",
    "        data      = [d.y for d in self.data]\n",
    "        self.y_mean    = _mean(    data)\n",
    "        self.y_std_dev = _std_dev( data)\n",
    "        self.y_abs_dev = _abs_dev( data)\n",
    "        \n",
    "        data      = [d.z for d in self.data]\n",
    "        self.z_mean    = _mean(    data)\n",
    "        self.z_std_dev = _std_dev( data)\n",
    "        self.z_abs_dev = _abs_dev( data)\n",
    "        \n",
    "        self.resultant = sum( [math.sqrt(d.x**2 + d.y**2 + d.z**2) for d in self.data])/float( len( data))\n",
    "        \n",
    "    def __str__( self):\n",
    "        fields = list()\n",
    "        if include_activity_letter:\n",
    "            fields += self.activity\n",
    "        fields += self.targets\n",
    "        fields += [self.x_mean, self.y_mean, self.z_mean]\n",
    "        fields += [self.x_std_dev, self.y_std_dev, self.z_std_dev]\n",
    "        fields += [self.x_abs_dev, self.y_abs_dev, self.z_abs_dev]\n",
    "        fields += [self.resultant]\n",
    "        if include_binned_distrubution:\n",
    "            fields += self.x_bin\n",
    "            fields += self.y_bin\n",
    "            fields += self.z_bin\n",
    "        return ','.join( [str(field) for field in fields])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators\n",
    "\n",
    "The memory footprint is kept managable with a couple by the **File Generator**, which provides tha path to one file at a time' and the **Time-series Data Chunker**, which puts together a new chunk one line at a time when requested so the whole file is never in memory.\n",
    "\n",
    "## File Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_generator( device, sensor):\n",
    "    for user in range(1600, 1651):\n",
    "        file_name = f\"data_{user}_{sensor}_{device}.txt\"\n",
    "        file_path = pathlib.Path.cwd() / 'raw' / device / sensor / file_name \n",
    "        yield file_path\n",
    "        \n",
    "        if test_only:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-series Data Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_second_intervals( csv_file_path):\n",
    "    '''This generator yields an array of records.\n",
    "    \n",
    "    csv_file - should have a unix time stamp in the first position.\n",
    "    '''\n",
    "    with open( csv_file_path) as fh:\n",
    "        reader = csv.reader( fh)\n",
    "        current_activity = 'A'\n",
    "        current_chunk = list()\n",
    "        for line in reader:\n",
    "            raw_data = RawTimeSeriesData( line)\n",
    "            if raw_data.activity == current_activity:\n",
    "                current_chunk.append( raw_data)\n",
    "                if len( current_chunk) == 200:\n",
    "                    yield TenSecondInterval( current_chunk)\n",
    "                    current_chunk = list()\n",
    "                    \n",
    "\n",
    "            else: \n",
    "                # In this case, there were not enough data to make a chunk.\n",
    "                current_activity = raw_data.activity\n",
    "                current_chunk = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building phone accel dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [01:17,  1.52s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building phone gyro dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:59,  1.17s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building watch accel dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [01:19,  1.57s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building watch gyro dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [01:24,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "labels = ''\n",
    "if include_activity_letter:\n",
    "    labels += 'activity_letter,'\n",
    "labels += 'activity_a,activity_b,activity_c,activity_d,activity_e,activity_f,activity_g,activity_h,activity_i,activity_j,activity_k,activity_l,activity_m,activity_o,activity_p,activity_q,activity_r,activity_s,cat_nonhand,cat_hand_general,cat_hand_eating,cat_hand_all,x_mean,y_mean,z_mean,x_std_dev,y_std_dev,z_std_dev,x_abs_dev,y_abs_dev,z_abs_dev,resultant'\n",
    "if include_binned_distrubution:\n",
    "    labels += ','\n",
    "    labels += ','.join(\n",
    "        [f'x_bin_{i}' for i in range(number_of_bins)] +\n",
    "        [f'y_bin_{i}' for i in range(number_of_bins)] +\n",
    "        [f'z_bin_{i}' for i in range(number_of_bins)]\n",
    "    )\n",
    "\n",
    "for device in ( 'phone', 'watch'):\n",
    "    if test_only:\n",
    "        print( labels)\n",
    "        break\n",
    "        \n",
    "    for sensor in ( 'accel', 'gyro'):\n",
    "        print( f\"Building {device} {sensor} dataset...\")\n",
    "        unnormalized_data = f\"{base_filename}unnormalized_{device}_{sensor}.csv\"\n",
    "        \n",
    "        with open( unnormalized_data, \"w\") as fh:\n",
    "            fh.write(labels)\n",
    "            for sensor_log in tqdm.tqdm(file_generator( device, sensor)):\n",
    "                for chunk in ten_second_intervals( sensor_log):\n",
    "                    fh.write( str(chunk) + \"\\n\")\n",
    " \n",
    "        targets = set(map( lambda i: f\"activity_{chr(i)}\", range( 97, 116))) | {'activity_letter', 'cat_nonhand', 'cat_hand_general', 'cat_hand_eating', 'cat_hand_all'}\n",
    "        df = pd.read_csv( unnormalized_data)\n",
    "        for col in df:\n",
    "            if col not in targets:\n",
    "                col_mean = df[col].mean()\n",
    "                col_std  = df[col].std()\n",
    "                df[ col] = (df[ col] - col_mean) / col_std\n",
    "        df.to_csv( f'{base_filename}normalized_{device}_{sensor}.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
